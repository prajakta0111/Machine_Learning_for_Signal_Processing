{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt \n",
    "from numpy import linalg as LA\n",
    "import scipy.io\n",
    "import librosa\n",
    "import IPython\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([27.74271844660194, 42.31183368869936],\n",
       " [6.9407562602656645, 4.392070855877006],\n",
       " [0.30518518518518517, 0.6948148148148148])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = len1 /(len1 + len2)\n",
    "p2 = len2 /(len1 + len2)\n",
    "allm=[n1,n2]\n",
    "alls=[std1,std2]\n",
    "allp=[p1,p2]\n",
    "\n",
    "allm, alls, allp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estep(disp,n,std):\n",
    "    e = 1/np.sqrt(2*np.pi*(std**2))\n",
    "    e *= (np.exp(-(((disp - n)**2)/(2*std**2))))\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new means are 20.843233835973912 and 40.1528286671005\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "    likelihood = np.array([estep(disparity,n,s) for n,s in zip(allm,alls)])\n",
    "    lp_sum = np.sum([l*p for l,p in zip(likelihood,allp)], axis = 0)\n",
    "    u_matrix = np.array([l*p/lp_sum for l,p in zip(likelihood,allp)])\n",
    "    new_means = np.array([np.sum(u*disparity)/np.sum(u) for u in u_matrix])\n",
    "    new_std = np.sqrt(np.array([np.sum(u*(disparity-n)**2)/np.sum(u) for u,n in zip(u_matrix,new_means)]))\n",
    "    new_p = np.array([np.mean(u) for u in u_matrix])\n",
    "    if np.all(np.abs(allm - new_means)) <= 0.001:\n",
    "        print(\"The new means are\", allm[0], \"and\", allm[1])\n",
    "        break\n",
    "    else:\n",
    "        allm=copy.deepcopy(new_means)\n",
    "        alls=copy.deepcopy(new_std)\n",
    "        allp=copy.deepcopy(new_p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conlusion:\n",
    "\n",
    "The GMM algorithm is better for this problem according to me. The values are ranged between 5 and 66. The means are better spaced in the first and third quartiles. The dataset is better clustered and balanced. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
